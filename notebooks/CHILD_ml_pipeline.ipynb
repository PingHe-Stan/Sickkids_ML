{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cf299fc",
   "metadata": {},
   "source": [
    "# CHILD ML Analysis\n",
    "    - ML Pipeline for CHILD Dataset from the very beginning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed73987",
   "metadata": {},
   "source": [
    "##### Step One: Feature Selection Strategies (Insights)\n",
    "\n",
    "##### Step Two: Making ML Pipelines\n",
    "\n",
    "##### Step Three: Tunning & Feature Engineering/Selection (data review) to Improve Performance (Insights)\n",
    "\n",
    "##### Step Four: Visualization of model performance\n",
    "\n",
    "##### Step Five: Paper, Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7e5692",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b852bf2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"# Preferences of autoformatting & Multiple Output\\n%load_ext nb_black\\n\\nfrom IPython.core.interactiveshell import InteractiveShell\\n\\nInteractiveShell.ast_node_interactivity = \\\"all\\\"\\n\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\nimport researchpy as rp  # For auto-statistics/EDA of dataframe\\nfrom tqdm.notebook import tqdm  # For process display\\nimport importlib  # For viewing library structure (dependancies, etc)\\n\\nimport sys\\n\\nsys.path.append(\\\"../src\\\")\\n\\nfrom data import *\\nfrom utils import *\\nfrom conf import *\\n\\nimport utils as UT\\nimport data as DT\\n\\n\\nimport random\\n\\nimport matplotlib.pyplot as plt\\nfrom sklearn.preprocessing import MinMaxScaler\";\n",
       "                var nbb_formatted_code = \"# Preferences of autoformatting & Multiple Output\\n%load_ext nb_black\\n\\nfrom IPython.core.interactiveshell import InteractiveShell\\n\\nInteractiveShell.ast_node_interactivity = \\\"all\\\"\\n\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\nimport researchpy as rp  # For auto-statistics/EDA of dataframe\\nfrom tqdm.notebook import tqdm  # For process display\\nimport importlib  # For viewing library structure (dependancies, etc)\\n\\nimport sys\\n\\nsys.path.append(\\\"../src\\\")\\n\\nfrom data import *\\nfrom utils import *\\nfrom conf import *\\n\\nimport utils as UT\\nimport data as DT\\n\\n\\nimport random\\n\\nimport matplotlib.pyplot as plt\\nfrom sklearn.preprocessing import MinMaxScaler\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preferences of autoformatting & Multiple Output\n",
    "%load_ext nb_black\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import researchpy as rp  # For auto-statistics/EDA of dataframe\n",
    "from tqdm.notebook import tqdm  # For process display\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "from data import *\n",
    "from utils import *\n",
    "from conf import *\n",
    "\n",
    "import utils as UT\n",
    "import data as DT\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eef5dc0",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e983002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ('../data/addon/Prenatal Q91PRNMH18WK.xlsx', '../output/CHILD_raw.xlsx', '../data/addon/breastfeeding data.xlsx', '../data/addon/Prenatal Q91PRNMH18WK.xlsx'), and merging\n",
      "The dataframe merged with more information is saved to ../output/ with name of CHILD_with_addon.xlsx\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# df_raw = generate_raw_xlsx()\\ndf_child = load_child_with_more()\";\n",
       "                var nbb_formatted_code = \"# df_raw = generate_raw_xlsx()\\ndf_child = load_child_with_more()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df_raw = generate_raw_xlsx()\n",
    "df_child = load_child_with_more()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1d5db83",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension of original dataframe for process is (3455, 157)\n",
      "Number of categorical features is:  56\n",
      "Number of numeric features is:  24\n",
      "Number of target variables is:  13\n",
      "Number of dropped features is:  63\n",
      "The difference of features of targeted and original dataframe is :{'Subject_Number'}\n",
      "The number of missing value for target label is: 809\n",
      "------------------------------------------------------\n",
      "Note: Target variable can be one of: \n",
      " ['Asthma_Diagnosis_3yCLA', 'Asthma_Diagnosis_5yCLA', 'Recurrent_Wheeze_1y', 'Recurrent_Wheeze_3y', 'Recurrent_Wheeze_5y', 'Wheeze_Traj_Type', 'Medicine_for_Wheeze_5yCLA', 'Viral_Asthma_3yCLA', 'Triggered_Asthma_3yCLA', 'Viral_Asthma_5yCLA', 'Triggered_Asthma_5yCLA', 'Cumulative_Wheeze_36m', 'Cumulative_Wheeze_60m']\n",
      "------------------------------------------------------\n",
      "****Target variable will be renamed to y for easy access.**** \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"df_targeted = target_selector(df_child, target_mapping={2: 1})\";\n",
       "                var nbb_formatted_code = \"df_targeted = target_selector(df_child, target_mapping={2: 1})\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_targeted = target_selector(df_child, target_mapping={2: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9e07d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 30 / 412 (7.3%) for asthma positive are dropped due to more than 10 missing value in the sample.\n",
      "\n",
      "The total number of dropped samples is 196\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"df_shrunk, X, y, df_dropped = sample_selector(df_targeted)\";\n",
       "                var nbb_formatted_code = \"df_shrunk, X, y, df_dropped = sample_selector(df_targeted)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_shrunk, X, y, df_dropped = sample_selector(df_targeted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2b41865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"df_shrunk.to_excel(\\\"../output/targeted_raw_child.xlsx\\\")\\n\\n# Restore raw data\\ndf = df_shrunk.copy()\\nX = df_shrunk.drop(columns=\\\"y\\\").copy()\\ny = df_shrunk[\\\"y\\\"].copy()\";\n",
       "                var nbb_formatted_code = \"df_shrunk.to_excel(\\\"../output/targeted_raw_child.xlsx\\\")\\n\\n# Restore raw data\\ndf = df_shrunk.copy()\\nX = df_shrunk.drop(columns=\\\"y\\\").copy()\\ny = df_shrunk[\\\"y\\\"].copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_shrunk\n",
    "\n",
    "# Restore raw data\n",
    "df = df_shrunk.copy()\n",
    "X = df_shrunk.drop(columns=\"y\").copy()\n",
    "y = df_shrunk[\"y\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4663b13a",
   "metadata": {},
   "source": [
    "###  Test Run of Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e589e7f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output columns will be: RIfrequency_earlier_report, RIseverity_earlier_report, RIfrequency_later_report, RIseverity_later_report\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Given the correlation threshhold of 0.95, the columns that will be removed are:['Dad_Inhalant', 'Mom_Inhalant']. Please see the following correlation:{'Dad_Inhalant <> Dad_Atopy': 1.0, 'Mom_Inhalant <> Mom_Atopy': 0.9983089637136121}\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Given the correlation threshhold of 0.7, the columns that will be considered to be dropped are:['BF_12m', 'Mother_Condition_Delivery', 'RIseverity_later_report', 'Noncold_Wheeze_3m', 'Mom_Inhalant', 'Antibiotics_Usage', 'BF_9m', 'Dad_Inhalant', 'RIseverity_earlier_report', 'First_10min_Measure', 'Parental_Asthma']. Please see the following correlation:{'BF_9m <> BF_Implied_Duration': 0.7779810254307755, 'BF_12m <> BF_Implied_Duration': 0.8004978873326745, 'Antibiotics_Usage <> Number_of_AntibioticsCourse': 0.938214467022626, 'Noncold_Wheeze_3m <> Epi_Noncold_Wheeze_3m': 0.931401423295512, 'First_10min_Measure <> F10min_Intubation': 0.7526751844410005, 'Mother_Condition_Delivery <> Prenatal_Other_Conditions': 0.702116574058341, 'BF_12m <> BF_9m': 0.7126265357449384, 'Parental_Asthma <> Mother_Asthma': 0.7224493457900305, 'Dad_Inhalant <> Dad_Atopy': 1.0, 'Mom_Inhalant <> Mom_Atopy': 0.9983089637136121, 'Noncold_Wheeze_3m <> Wheeze_3m': 0.7033503330050029, 'RIseverity_earlier_report <> RIfrequency_earlier_report': 0.7513468264373363, 'RIseverity_later_report <> RIfrequency_later_report': 0.8312039766836145}\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Given the missingness threshhold of 0.05, the columns that will be considered to be dropped are:  ['PSS_36week', 'PSS_18week', 'CSED_18week', 'PSS_6m', 'PSS_12m', 'CSED_6m', 'CSED_12m', 'Analgesics_usage_delivery', 'Jaundice_Birth', 'Complications_Birth', 'Home_Furry_Pets_6m', 'Home_New_Furnitures_6m', 'Home_Presence_Smoke_6m', 'Father_Asthma', 'Parental_Asthma', 'Dad_Atopy', 'Dad_Food', 'Dad_Inhalant', 'First_10min_Measure']. Please see the following missingness:{'PSS_36week': 0.05061224489795919, 'PSS_18week': 0.06775510204081632, 'CSED_18week': 0.06816326530612245, 'PSS_6m': 0.11387755102040817, 'PSS_12m': 0.11183673469387755, 'CSED_6m': 0.11591836734693878, 'CSED_12m': 0.11183673469387755, 'Analgesics_usage_delivery': 0.05551020408163265, 'Jaundice_Birth': 0.061224489795918366, 'Complications_Birth': 0.05959183673469388, 'Home_Furry_Pets_6m': 0.11061224489795918, 'Home_New_Furnitures_6m': 0.11061224489795918, 'Home_Presence_Smoke_6m': 0.11183673469387755, 'Father_Asthma': 0.12122448979591836, 'Parental_Asthma': 0.10326530612244898, 'Dad_Atopy': 0.17346938775510204, 'Dad_Food': 0.17387755102040817, 'Dad_Inhalant': 0.17346938775510204, 'First_10min_Measure': 0.10040816326530612}\n",
      "---------------------------------------------------------------------------------------------------\n",
      "The finalized dropped columns are ['Dad_Inhalant', 'First_10min_Measure', 'Mom_Inhalant', 'Parental_Asthma'] with two factor dropped columns {'Dad_Inhalant', 'First_10min_Measure', 'Parental_Asthma'} and repetition dropped ['Dad_Inhalant', 'Mom_Inhalant']\n",
      "All those with missing value will be imputated, the features with number of missing values are:  (['No_of_Pregnancy', 'Gest_Days', 'Prenatal_Second_Hand', 'Prenatal_Maternal_Smoke', 'Weight_0m', 'BF_Status_6m', 'Mother_Asthma', 'Apgar_Score_1min', 'Mom_Atopy', 'Apgar_Score_5min', 'Mom_Food', 'Wheeze_3m', 'RIfrequency_later_report', 'RIseverity_later_report', 'Weight_12m', 'BF_12m', 'BF_9m', 'Mother_Condition_Delivery', 'Noncold_Wheeze_3m', 'Respiratory_Problems_Birth', 'Anesthetic_delivery', 'Epi_Noncold_Wheeze_3m', 'Stay_Duration_Hospital', 'Weight_3m', 'CSED_36week', 'PSS_36week', 'Analgesics_usage_delivery', 'Complications_Birth', 'Jaundice_Birth', 'PSS_18week', 'CSED_18week', 'Home_New_Furnitures_6m', 'Home_Furry_Pets_6m', 'CSED_12m', 'Home_Presence_Smoke_6m', 'PSS_12m', 'PSS_6m', 'CSED_6m', 'Father_Asthma', 'Dad_Atopy', 'Dad_Food'], [2, 3, 12, 14, 19, 19, 19, 22, 22, 22, 25, 48, 51, 51, 56, 56, 56, 68, 73, 78, 91, 93, 95, 103, 117, 124, 136, 146, 150, 166, 167, 271, 271, 274, 274, 274, 279, 284, 297, 425, 426])\n",
      "In which columns with categorical values are:  ['Study_Center', 'Gender', 'BF_Status_3m', 'BF_Status_6m', 'Child_Ethinicity', 'Mode_of_delivery']\n",
      "Given the correlation threshhold of 0.95, the columns that will be removed are:['CSED_6m_Missing', 'Home_Furry_Pets_6m_Missing', 'Dad_Food_Missing', 'CSED_36week_Missing', 'CSED_12m_Missing', 'CSED_18week_Missing', 'Home_Presence_Smoke_6m_Missing']. Please see the following correlation:{'CSED_36week_Missing <> PSS_36week_Missing': 0.9699058395018689, 'CSED_18week_Missing <> PSS_18week_Missing': 0.9967832108354368, 'CSED_6m_Missing <> PSS_6m_Missing': 0.9900160742901514, 'CSED_12m_Missing <> PSS_12m_Missing': 1.0, 'Dad_Food_Missing <> Dad_Atopy_Missing': 0.998578947413681, 'Home_Presence_Smoke_6m_Missing <> Home_New_Furnitures_6m_Missing': 0.9938256339857658, 'Home_Furry_Pets_6m_Missing <> Home_New_Furnitures_6m_Missing': 1.0, 'Home_Furry_Pets_6m_Missing <> Home_Presence_Smoke_6m_Missing': 0.9938256339857658}\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"df_for_ml = generate_trainable_dataset(X, y, add_indicator_threshold=1000)\";\n",
       "                var nbb_formatted_code = \"df_for_ml = generate_trainable_dataset(X, y, add_indicator_threshold=1000)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_for_ml = generate_trainable_dataset(X, y, add_indicator_threshold=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f9b214c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"# Backup df_for_ml\\ndf_for_ml_backup = df_for_ml.copy()\";\n",
       "                var nbb_formatted_code = \"# Backup df_for_ml\\ndf_for_ml_backup = df_for_ml.copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Backup df_for_ml\n",
    "df_for_ml_backup = df_for_ml.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8195c53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.844082\n",
       "1.0    0.155918\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0    2068\n",
       "1.0     382\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(2450, 106)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(2450,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"df_for_ml.y.value_counts(normalize=True)\\ndf_for_ml.y.value_counts(normalize=False)\\n# Restore X,y for ML modelling\\nX = df_for_ml.drop(columns=\\\"y\\\")\\ny = df_for_ml.y\\nX.shape\\ny.shape\";\n",
       "                var nbb_formatted_code = \"df_for_ml.y.value_counts(normalize=True)\\ndf_for_ml.y.value_counts(normalize=False)\\n# Restore X,y for ML modelling\\nX = df_for_ml.drop(columns=\\\"y\\\")\\ny = df_for_ml.y\\nX.shape\\ny.shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_for_ml.y.value_counts(normalize=True)\n",
    "df_for_ml.y.value_counts(normalize=False)\n",
    "# Restore X,y for ML modelling\n",
    "X = df_for_ml.drop(columns=\"y\")\n",
    "y = df_for_ml.y\n",
    "X.shape\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d7a63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaled ML using MinMaxScaler()\n",
    "df_ml_scaled = pd.DataFrame(\n",
    "    MinMaxScaler().fit_transform(df_for_ml), columns=df_for_ml.columns\n",
    ")\n",
    "\n",
    "for i in df_ml_scaled.columns:\n",
    "    df_ml_scaled[i] = df_ml_scaled[i].astype(\"float16\")\n",
    "\n",
    "X = df_ml_scaled.drop(columns=\"y\")\n",
    "y = df_ml_scaled.y\n",
    "X.shape\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e164bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_X_df = X.corr()\n",
    "repetition_drop = []  # Feature will be dropped because of high correlation\n",
    "repetition_dict = {}\n",
    "\n",
    "for i, col in enumerate(corr_X_df.columns):\n",
    "    for i_name in corr_X_df[col].index[i + 1 :]:\n",
    "        if corr_X_df[col][i_name] > 0.95:\n",
    "            repetition_drop.extend([i_name])\n",
    "            repetition_dict[\" <> \".join([i_name, corr_X_df[col].name])] = corr_X_df[\n",
    "                col\n",
    "            ][i_name]\n",
    "\n",
    "repetition_drop\n",
    "repetition_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daa6e66",
   "metadata": {},
   "source": [
    "## Now begins the INTERESTING ML Journey!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbb2fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(view_module_functions(UT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abda9304",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_summary = df_summary(X)\n",
    "X_summary.sort_values(by=\"Variance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b6bdcb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_prop = view_y_proportions(df_ml_scaled, df_ml_scaled.columns[:-1], 0)\n",
    "\n",
    "view_y_proportions(df_ml_scaled, df_ml_scaled.columns[:-1], 0.5)[\n",
    "    view_y_proportions(\n",
    "        df_ml_scaled, df_ml_scaled.columns[:-1], 0.5\n",
    "    ).Asthma_Proportion_over_thresh\n",
    "    < 10\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fad571",
   "metadata": {},
   "source": [
    "#### Additional: Statistic Analysis for F10min Mask related to Asthma Outcome\n",
    "\n",
    "Pingouin, statsmodel(table,proportion), scipy, sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c1b3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three Package to obtain P value for chi square test for F10min Oxygen Mask Stats\n",
    "# Scipy Based\n",
    "# One\n",
    "import pingouin as pg\n",
    "\n",
    "expected, observed, stats = pg.chi2_independence(\n",
    "    df_ml_scaled, x=\"F10min_Oxygen_Mask\", y=\"y\", correction=False\n",
    ")\n",
    "\n",
    "observed, expected, stats\n",
    "\n",
    "_, _, stats = pg.chi2_independence(\n",
    "    df_ml_scaled, x=\"Prenatal_Hypotension\", y=\"y\", correction=False\n",
    ")\n",
    "\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae13b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two: Scipy - Required to create contingency table as input\n",
    "# Need to create a contingency table first, which can be realized using pd.crosstab\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "contingency_f10m_Oxy = pd.crosstab(df_ml_scaled.F10min_Oxygen_Mask, df_ml_scaled.y)\n",
    "\n",
    "chi2_contingency(contingency_f10m_Oxy.values, correction=False)\n",
    "\n",
    "print(\n",
    "    \"In statistics, Yates's correction for continuity (or Yates's chi-squared test) is used in certain situations when testing for independence in a contingency table. It aims at correcting the error introduced by assuming that the discrete probabilities of frequencies in the table can be approximated by a continuous distribution (chi-squared). In some cases, Yates's correction may adjust too far, and so its current use is limited.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d47f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three: Statsmodel\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# sm_f10oxy_table = sm.stats.Table(contingency_f10m_Oxy.values)\n",
    "sm_f10oxy_table = sm.stats.Table.from_data(df_ml_scaled[[\"F10min_Oxygen_Mask\", \"y\"]])\n",
    "\n",
    "print(f\"Observed Table:\\n {sm_f10oxy_table.table_orig}\")\n",
    "print(f\"Expected Table:\\n {sm_f10oxy_table.fittedvalues}\")\n",
    "print(\n",
    "    f\"Pearson Residuals:\\n {sm_f10oxy_table.resid_pearson}\"\n",
    ")  # view Residuals which identify particular cells that most strongly violate independence\n",
    "\n",
    "print(\"\\n----------------Independence/Association test----------------\")\n",
    "print(\"\\nNominal Association:\\n\", sm_f10oxy_table.test_nominal_association())\n",
    "print(\"\\nOrdinal Association:\\n\", sm_f10oxy_table.test_ordinal_association())\n",
    "print(f\"\\nChi Square Contribution:\\n{sm_f10oxy_table.chi2_contribs}\")\n",
    "print(\n",
    "    \"\\n----------------Local Odd Ratio----------------:\\n{}\".format(\n",
    "        sm_f10oxy_table.local_oddsratios\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    f\"Contingency table odd ratio: {sm.stats.Table2x2(contingency_f10m_Oxy.values).oddsratio}\"\n",
    ")\n",
    "\n",
    "\n",
    "# Three-2: Statsmodel Proportion Test\n",
    "# Proportion Chi-Square Test\n",
    "print(\"\\n----------------Proportion Chi-Square Test----------------\")\n",
    "from statsmodels.stats.proportion import (\n",
    "    proportions_chisquare,\n",
    "    proportion_effectsize,\n",
    ")  # No indexing needed\n",
    "\n",
    "f10mask_no_group_observation = np.sum(df_ml_scaled.F10min_Oxygen_Mask != 1)\n",
    "f10mask_yes_group_observation = np.sum(df_ml_scaled.F10min_Oxygen_Mask == 1)\n",
    "\n",
    "f10mask_no_asthma_count = np.sum(df_ml_scaled[df_ml_scaled.F10min_Oxygen_Mask != 1].y)\n",
    "f10mask_yes_asthma_count = np.sum(df_ml_scaled[df_ml_scaled.F10min_Oxygen_Mask == 1].y)\n",
    "\n",
    "(chi2, chi2_p_value, expected) = proportions_chisquare(\n",
    "    count=[f10mask_no_asthma_count, f10mask_yes_asthma_count],\n",
    "    nobs=[f10mask_no_group_observation, f10mask_yes_group_observation],\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"\\nAsthma Outcome Proportion Chi Square Test:\\nchi2: %f \\t p_value: %f\"\n",
    "    % (chi2, chi2_p_value)\n",
    ")\n",
    "\n",
    "\n",
    "asthma_no_group_observation = np.sum(df_ml_scaled.y != 1)\n",
    "asthma_yes_group_observation = np.sum(df_ml_scaled.y == 1)\n",
    "\n",
    "asthma_no_f10mask_count = np.sum(df_ml_scaled[df_ml_scaled.y != 1].F10min_Oxygen_Mask)\n",
    "asthma_yes_f10mask_count = np.sum(df_ml_scaled[df_ml_scaled.y == 1].F10min_Oxygen_Mask)\n",
    "\n",
    "(chi2, chi2_p_value, expected) = proportions_chisquare(\n",
    "    count=[asthma_no_f10mask_count, asthma_yes_f10mask_count],\n",
    "    nobs=[asthma_no_group_observation, asthma_yes_group_observation],\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"\\nF10m Mask Outcome Proportion Chisquare Test:\\nchi2: %f \\t p_value: %f\"\n",
    "    % (chi2, chi2_p_value)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ed2a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Discrepancy: P-value of chi square test between Scipy and Statsmodel\")\n",
    "\n",
    "print(\n",
    "    f\"\\nFor Scipy with correction:\\npvalue: {chi2_contingency(contingency_f10m_Oxy.values)[1]}\"\n",
    ")\n",
    "print(\n",
    "    f\"\\nFor Scipy without correction:\\npvalue: {chi2_contingency(contingency_f10m_Oxy.values, correction=False)[1]}\"\n",
    ")\n",
    "\n",
    "print(f\"\\nFor Statsmodel:\\n{sm_f10oxy_table.test_nominal_association()}\")\n",
    "\n",
    "\n",
    "print(\n",
    "    \"\\nExplanation:\\n\\nScipy uses the continuity correction, Statsmodels does not. If you pass correction=False to the scipy test, then the results will be identical.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966e16ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Four: Sklearn - CHI2\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "chi2(df_ml_scaled.F10min_Mask_Ventilation.values.reshape(-1, 1), df_ml_scaled.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9388f96",
   "metadata": {},
   "source": [
    "### ML Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae35558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "\n",
    "# Feature selection\n",
    "from sklearn.feature_selection import (\n",
    "    SelectPercentile,\n",
    "    SelectKBest,\n",
    "    SelectFwe,\n",
    "    SelectFpr,\n",
    "    SelectFromModel,\n",
    "    chi2,\n",
    "    mutual_info_classif,\n",
    "    f_classif,\n",
    "    SequentialFeatureSelector,\n",
    "    RFECV,\n",
    ")\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Imbalance Learn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, LassoLarsCV, LassoCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Model Metrics, Parameters, Evaluation\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold,\n",
    "    GridSearchCV,\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    ")\n",
    "\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    roc_curve,\n",
    "    classification_report,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fd669d",
   "metadata": {},
   "source": [
    "### Feature Selection   <a id='0'></a> \n",
    "\n",
    "1. [Lasso](#lasso)\n",
    "2. [Chi2](#chi2)\n",
    "3. [f_value](#f_classif)\n",
    "4. [FalsePositiveRate](#fpr)\n",
    "5. [p_value](#fwe)\n",
    "6. [mutual_information](#mutal)\n",
    "7. [Recursive Feature Elimination](#RFE)\n",
    "8. [SelectFromModel](#selm)\n",
    "9. [permutation_importance](#permutation)\n",
    "10. [SequentialFeatureSelector](#sequentialgreed)\n",
    "\n",
    "### Feature Engineering\n",
    "1. [PCA](#pca)\n",
    "2. [FeatureAgglomeration](#clusteragglomeration)\n",
    "3. [Derived_New_Features_with_Expertise_and_Logic](#derivenewfeature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ff4369",
   "metadata": {},
   "source": [
    "#### (1) Lasso - Observation - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa745e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.style.available\n",
    "# plt.style.use(\"seaborn-bright\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c67e3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic Alphas with StratifiedKfold\n",
    "skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=1015)\n",
    "model = LassoLarsCV(cv=skf).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c902f77a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 12))\n",
    "columns_of_total = X.shape[1]\n",
    "start = 0\n",
    "end = X.shape[1]\n",
    "number_of_display = end - start\n",
    "\n",
    "cm = iter(plt.get_cmap(\"Set1\")(np.linspace(0, 1, number_of_display)))\n",
    "for i in range(start, end):\n",
    "    c = next(cm)\n",
    "    _ = ax.plot(\n",
    "        model.alphas_, model.coef_path_.T[:, i], c=c, alpha=0.8, label=X.columns[i]\n",
    "    )\n",
    "\n",
    "\n",
    "lassocv_df = pd.DataFrame(\n",
    "    data=model.coef_path_.T, columns=X.columns, index=model.alphas_\n",
    ")\n",
    "\n",
    "y_pos_ser = lassocv_df.iloc[-1:].T.iloc[:, 0][lassocv_df.iloc[-1:].T.iloc[:, 0] != 0]\n",
    "x_pos = float(lassocv_df.iloc[-1:].T.columns.values)\n",
    "x_pos_list = [x_pos for i in range(len(y_pos_ser))]\n",
    "\n",
    "for x_t, y_t, text in zip(x_pos_list, y_pos_ser.values, y_pos_ser.index):\n",
    "    axtxt = ax.text(\n",
    "        x_t - 0.00005,\n",
    "        y_t,\n",
    "        text,  # Used to format it K representation\n",
    "        color=\"black\",\n",
    "        rotation=\"horizontal\",\n",
    "        size=\"large\",\n",
    "    )\n",
    "\n",
    "ax.legend(X.columns[start:end], bbox_to_anchor=(1, 1))\n",
    "\n",
    "plt.xlim([0.00015, 0.00085])\n",
    "plt.ylabel(\"Lasso Regression CV\")\n",
    "plt.xlabel(\"Regularization Factor - Alphas\")\n",
    "plt.title(\"Regression Coefficient Progression for Lasso Path\")\n",
    "\n",
    "fig.savefig(\"../images/lasso_progression\",dpi=300,bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f354a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_y_proportions(\n",
    "    df_for_ml, lassocv_df.sum()[lassocv_df.sum() != 0].sort_values().index, 0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56667499",
   "metadata": {},
   "source": [
    "#### Lasso - Observation - 2 - All features decreasing pattern   <a id='lasso'></a>\n",
    "\n",
    "[return](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eaa053",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_dict = {}\n",
    "for alp in tqdm(np.arange(0.000001, 0.0009, 0.000005)):\n",
    "    lasso_model = Lasso(alpha=alp).fit(X, y)\n",
    "    coef_dict[alp] = list(lasso_model.coef_)\n",
    "\n",
    "res = pd.DataFrame(data=coef_dict.values(), columns=X.columns, index=coef_dict.keys()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37d8684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For those with bitter coefficient (impact)\n",
    "res[0.000001][abs(res[0.000001]) > 0.05].sort_values().index\n",
    "view_y_proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b67336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.color_palette(\"YlOrBr\", as_cmap=True)\n",
    "fig, ax = plt.subplots(figsize=(40, 40))\n",
    "sns.heatmap(res.iloc[:, :], vmax=0.2, vmin=-0.2, cmap=\"vlag\", ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30684aeb",
   "metadata": {},
   "source": [
    "#### (2) Chi2 & SelectPercentile  <a id='chi2'></a>\n",
    "\n",
    "[return](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eef568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([(\"chi2\", SelectPercentile(chi2)), (\"rfc\", RandomForestClassifier())])\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=1020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c804da0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# Plot the cross-validation score as a function of percentile of features\n",
    "score_means = list()\n",
    "score_stds = list()\n",
    "percentiles = (1, 5, 10, 15, 20, 30, 40, 60, 80, 90, 100)\n",
    "\n",
    "for percentile in tqdm(percentiles):\n",
    "    clf.set_params(chi2__percentile=percentile)\n",
    "    this_scores = cross_val_score(clf, X, y, cv=skf, scoring=\"precision\")\n",
    "    score_means.append(this_scores.mean())\n",
    "    score_stds.append(this_scores.std())\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.errorbar(percentiles, score_means, np.array(score_stds))\n",
    "plt.title(\n",
    "    \"Performance of the RandomForest-Chi2 varying the percentile of features selected\"\n",
    ")\n",
    "plt.xticks(np.linspace(0, 100, 11, endpoint=True))\n",
    "plt.xlabel(\"Percentile\")\n",
    "plt.ylabel(\"Precision Score\")\n",
    "plt.axis(\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e80171",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_perc = SelectPercentile(chi2, percentile=30)\n",
    "chi_perc.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9fe922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.columns[chi_perc.get_support()]\n",
    "chi_perc.get_feature_names_out()\n",
    "len(chi_perc.get_feature_names_out())\n",
    "\n",
    "chi2_res = pd.DataFrame(\n",
    "    [list(chi_perc.pvalues_), list(chi_perc.scores_)],\n",
    "    index=[\"P_value\", \"Scores\"],\n",
    "    columns=X.columns,\n",
    ").T\n",
    "\n",
    "chi2_res[chi2_res.P_value < 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783353af",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_y_proportions(df_ml_scaled, chi2_res[chi2_res.P_value < 0.05].index, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5148de8f",
   "metadata": {},
   "source": [
    "#### (3) F_classif & SelectPercentile  <a id='f_classif'></a>\n",
    "\n",
    "[return](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8c3b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([(\"fvalue\", SelectKBest(f_classif)), (\"xgb\", XGBClassifier())])\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=1020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964a099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# Plot the cross-validation score as a function of percentile of features\n",
    "score_means = list()\n",
    "score_stds = list()\n",
    "k_best = (10, 20, 25, 30, 35, 40, 50, 60, 70, 90, \"all\")\n",
    "\n",
    "for i in tqdm(k_best):\n",
    "    clf.set_params(fvalue__k=i)\n",
    "    this_scores = cross_val_score(clf, X, y, cv=skf, scoring=\"f1\")\n",
    "    score_means.append(this_scores.mean())\n",
    "    score_stds.append(this_scores.std())\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.errorbar(percentiles, score_means, np.array(score_stds))\n",
    "plt.title(\"Performance of the XGB-f_value varying the number of features selected\")\n",
    "plt.xticks(np.linspace(0, 100, 11, endpoint=True))\n",
    "plt.xlabel(\"Percentile\")\n",
    "plt.ylabel(\"Precision Score\")\n",
    "plt.axis(\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0241ac9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_bestk = SelectKBest(f_classif, k=40)\n",
    "f_bestk.fit_transform(X, y)\n",
    "\n",
    "f_bestk.get_feature_names_out()\n",
    "len(f_bestk.get_feature_names_out())\n",
    "\n",
    "f_res = pd.DataFrame(\n",
    "    [list(chi_perc.pvalues_), list(chi_perc.scores_)],\n",
    "    index=[\"P_value\", \"Scores\"],\n",
    "    columns=X.columns,\n",
    ").T\n",
    "\n",
    "f_res[f_res.P_value < 0.05]\n",
    "\n",
    "f_res[f_res.Scores > 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbef471",
   "metadata": {},
   "source": [
    "#### (4) False Positive Rate  <a id='fpr'></a>\n",
    "\n",
    "[return](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153434cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_res = SelectFpr(score_func=chi2, alpha=0.05)\n",
    "fpr_res.fit_transform(X, y).shape\n",
    "col_temp = pd.DataFrame(fpr_res.pvalues_.reshape(1,len(X.columns)),columns=X.columns).T.loc[:,0][pd.DataFrame(fpr_res.pvalues_.reshape(1,len(X.columns)),columns=X.columns).T.loc[:,0] <= 0.05].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acaeb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = fpr_res.fit_transform(X, y)\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fca5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = X[col_temp].values\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4c6283",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(d1 != d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9516c304",
   "metadata": {},
   "source": [
    "#### (5) P_value  <a id='fwe'></a>\n",
    "\n",
    "Use P-value instead of score to select features\n",
    "\n",
    "[return](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45b75ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "d3 = SelectFwe(chi2, alpha=0.05).fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9ca8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(d1 != d3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ad50bd",
   "metadata": {},
   "source": [
    "#### (6) Mutual Information  <a id='mutal'></a>\n",
    "\n",
    "Use Mutual Information to select features for classification\n",
    "\n",
    "[return](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faf82be",
   "metadata": {},
   "outputs": [],
   "source": [
    "mic = mutual_info_classif(X, y, random_state=1)\n",
    "fig, ax = plt.subplots(figsize=(10, 20))\n",
    "mic_df = (\n",
    "    pd.DataFrame({\"feature\": X.columns, \"vimp\": mic})\n",
    "    .set_index(\"feature\")\n",
    "    .sort_values(by=\"vimp\", ascending=True)\n",
    ")\n",
    "mic_df[mic_df.vimp != 0].shape[0]\n",
    "mic_df[mic_df.vimp != 0].plot.barh(ax=ax)\n",
    "mic_df[mic_df.vimp != 0].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335f28f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_y_proportions(df_ml_scaled, mic_df[mic_df.vimp != 0].index.values, 0.2)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0024bb7",
   "metadata": {},
   "source": [
    "#### (7) Recursive Feature Elimination  <a id='RFE'></a>\n",
    "\n",
    "Use Recursive Feature Elimination to select features for classification\n",
    "\n",
    "[return](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17110f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.model_selection import RFECV\n",
    "\n",
    "res_index = res[0.000001][abs(res[0.000001]) > 0.05].sort_values().index\n",
    "\n",
    "lasso_index = lassocv_df.sum()[lassocv_df.sum() != 0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa28810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(list(res_index) + list(lasso_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a411bdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(2)\n",
    "# visualizer = RFECV(RandomForestClassifier(), cv=cv, scoring=\"average_precision\")\n",
    "# visualizer1 = RFECV(RandomForestClassifier(), cv=cv, scoring=\"precision_weighted\")\n",
    "visualizer1 = RFECV(RandomForestClassifier(), cv=cv, scoring=\"roc_auc\")\n",
    "visualizer1.fit(\n",
    "    X[list(set(list(res_index) + list(lasso_index)))], y\n",
    ")  # Fit the data to the visualizer\n",
    "visualizer1.show()  # Finalize and render the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1949ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_y_proportions(df_ml_scaled, list(set(list(res_index) + list(lasso_index))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415204d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data=visualizer1.ranking_,\n",
    "    index=X[list(set(list(res_index) + list(lasso_index)))].columns,\n",
    "    columns=[\"ranking\"],\n",
    ").sort_values(by=\"ranking\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8c473f",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_all = X.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbf19c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(2)\n",
    "# visualizer = RFECV(RandomForestClassifier(), cv=cv, scoring=\"average_precision\")\n",
    "# visualizer1 = RFECV(RandomForestClassifier(), cv=cv, scoring=\"precision_weighted\")\n",
    "visualizer2 = RFECV(RandomForestClassifier(), cv=cv, scoring=\"roc_auc\")\n",
    "visualizer2.fit(X[set_to_see], y)  # Fit the data to the visualizer\n",
    "visualizer2.show()  # Finalize and render the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3144f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data=visualizer2.ranking_, index=X[set_to_see].columns, columns=[\"ranking\"],\n",
    ").sort_values(by=\"ranking\").T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670e56dd",
   "metadata": {},
   "source": [
    "#### (8) SelectFromModel <a id='selm'></a>\n",
    "\n",
    "Use Recursive Feature Elimination to select features for classification\n",
    "\n",
    "[return](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1149b074",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = LassoCV(cv=skf).fit(X, y)\n",
    "importance = np.abs(lasso.coef_)\n",
    "feature_names = np.array(X.columns)\n",
    "plt.bar(height=importance, x=feature_names)\n",
    "plt.title(\"Feature importances via coefficients\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79b92ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfm = SelectFromModel(estimator=LassoCV(cv=skf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcc9cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfm.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c53ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfm.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8562f43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X.columns[sfm.get_support()]\n",
    "sfm.estimator_.coef_\n",
    "\n",
    "# coef_ser = pd.Series(sfm.estimator_.coef_.reshape(99,), index=X.columns, name=\"coef\")[\n",
    "#     abs(coef_ser) > 0\n",
    "# ]\n",
    "# coef_ser\n",
    "\n",
    "importance = np.abs(coef_ser.values)\n",
    "feature_names = np.array(coef_ser.index)\n",
    "plt.bar(height=importance, x=feature_names)\n",
    "plt.title(\"Feature importances via coefficients\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e649ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X[X.columns[sfm.get_support()]], y, test_size=0.33, stratify=y, random_state=43\n",
    "# )\n",
    "\n",
    "# clf_knn = KNeighborsClassifier(n_neighbors=3, weights=\"distance\")\n",
    "# clf_knn.fit(X_train, y_train)\n",
    "# y_pred = clf_knn.predict(X_test)\n",
    "# confusion_matrix(y_test, y_pred)\n",
    "# print(classification_report(y_test, y_pred))\n",
    "# f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b83a7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X[X.columns[sfm.get_support()]], y, test_size=0.33, stratify=y, random_state=42\n",
    "# )\n",
    "\n",
    "# clf_lr = LogisticRegression()\n",
    "# clf_lr.fit(X_train, y_train)\n",
    "# y_pred = clf_lr.predict(X_test)\n",
    "# confusion_matrix(y_test, y_pred)\n",
    "# print(classification_report(y_test, y_pred))\n",
    "# f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dae2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfm_rf = SelectFromModel(estimator=RandomForestClassifier(), threshold=\"mean\")\n",
    "sfm_rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79323476",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfm_rf.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f338458",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_ser = pd.Series(\n",
    "    sfm_rf.estimator.feature_importances_.reshape(99,),\n",
    "    index=X.columns,\n",
    "    name=\"feature_importance\",\n",
    ")\n",
    "rf_ser.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3800304b",
   "metadata": {},
   "source": [
    "#### (9) Permutation Importance <a id='permutation'></a>\n",
    "[return](#0)\n",
    "\n",
    "Permutation feature importance is a model inspection technique that can be used for any fitted estimator when the data is tabular. This is especially useful for non-linear or opaque estimators. The permutation feature importance is defined to be the decrease in a model score when a single feature value is randomly shuffled. This procedure breaks the relationship between the feature and the target, thus the drop in the model score is indicative of how much the model depends on the feature. This technique benefits from being model agnostic and can be calculated many times with different permutations of the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5988a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomsubset_permutation_importance(*, clf: object, percentile_of_features: float):\n",
    "    \"\"\"\n",
    "    As when all features are included, none of the feature will have any importance, I therefore created this function \n",
    "    to view the feature importance of a random subset of features.\n",
    "    : para: percentile_of_features\n",
    "    : para: clf: a classification algorithm\n",
    "    : return: a visualization of feature importance for current subset of features\n",
    "    \"\"\"\n",
    "    number_of_features = int(len(X.columns.values) * percentile_of_features)\n",
    "    selected_columns = random.sample(list(X.columns.values), number_of_features)\n",
    "    clf.fit(X[selected_columns], y)\n",
    "    result = permutation_importance(\n",
    "        clf, X[selected_columns], y, n_repeats=10, random_state=1012, scoring=\"roc_auc\",\n",
    "    )\n",
    "    perm_sorted_idx = result.importances_mean.argsort()\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.barh(\n",
    "        width=result.importances_mean[perm_sorted_idx].T, y=X.columns[perm_sorted_idx],\n",
    "    )\n",
    "    r = result\n",
    "    for i in r.importances_mean.argsort()[::-1]:\n",
    "        if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "            print(\n",
    "                f\"{X.columns[i]:<8}\"\n",
    "                f\"{r.importances_mean[i]:.3f}\"\n",
    "                f\" +/- {r.importances_std[i]:.3f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5acef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomsubset_permutation_importance(\n",
    "    clf=RandomForestClassifier(), percentile_of_features=0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7f51d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shrunk[df_shrunk.Home_Furry_Pets_6m.isna()][\n",
    "    df_shrunk.columns[df_shrunk.columns.str.contains(\"Home|Asthma|^y$\")]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b072c59",
   "metadata": {},
   "source": [
    "### ML Pipeline Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138ee8ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234ce08f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5928bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39bf931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88b88be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91466288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0f6187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef06659b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053979c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6987df62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
